#!/usr/bin/env python3
"""
LangChain RAG-based Vulnerability Classifier
Enriches vulnerability data with CWE, MITRE ATT&CK, and RL agent hints
"""

import json
import os
import time
import yaml
from datetime import datetime
from typing import Dict, List, Optional, Any, Union
from pathlib import Path

# Import UniversalLLMClient
from apfa_agent.core.llm_client import UniversalLLMClient

# Import from same directory (Classifier/)
import sys
import os
sys.path.insert(0, os.path.dirname(__file__))
from knowledge_base import KnowledgeBase, get_knowledge_base  # type: ignore


class VulnerabilityClassifier:
    """
    Hybrid vulnerability classifier using pattern matching, CVE lookup, and optional RAG
    """
    
    VERSION = "1.0.0"
    
    def __init__(
        self,
        mode: str = "hybrid",
        enable_rag: bool = False,
        confidence_threshold: float = 0.7,
        api_key: Optional[str] = None
    ):
        """
        Initialize the vulnerability classifier
        
        Args:
            mode: Classification mode ("pattern", "hybrid", "rag")
            enable_rag: Enable RAG-based classification for complex cases
            confidence_threshold: Minimum confidence for pattern matching
            api_key: API key (optional, used if specific client needs it)
        """
        self.mode = mode
        self.enable_rag = enable_rag
        self.confidence_threshold = confidence_threshold
        
        # Initialize knowledge base
        self.kb = get_knowledge_base()
        
        # Initialize LLM if RAG is enabled
        self.llm = None
        if self.enable_rag:
            self._init_llm(api_key)
        
        # Stats tracking
        self.stats = {
            "total_classified": 0,
            "pattern_matches": 0,
            "cve_lookups": 0,
            "rag_classifications": 0,
            "fallback_generic": 0
        }
    
    def _init_llm(self, api_key: Optional[str] = None):
        """Initialize UniversalLLMClient for RAG-based classification"""
        try:
            # We use the default config loading mechanism of UniversalLLMClient
            # If api_key is provided, we might need to inject it, but UniversalLLMClient 
            # usually loads from agent_config.yaml or env vars.
            # For now, we instantiate it with empty config to let it auto-discover.
            
            config = {} 
            if api_key:
                # If specific key provided, we might need a way to pass it, 
                # but UniversalLLMClient structure is config-based.
                # We'll assume env vars are set or config file exists.
                pass
                
            self.llm = UniversalLLMClient(config=config)
            
            # Verify LLM is working (optional, UniversalLLMClient does its own checks)
            if not self.llm.model and not self.llm.use_dummy:
                 print("WARNING: UniversalLLMClient initialized but no model found.")
                 
        except Exception as e:
            print(f"WARNING: Failed to initialize LLM: {e}. RAG mode disabled.")
            self.enable_rag = False
    
    def classify_vulnerability(self, vuln: Dict[str, Any]) -> Dict[str, Any]:
        """
        Classify a single vulnerability
        
        Args:
            vuln: Vulnerability data dict (from parser)
        
        Returns:
            Enriched vulnerability with classification
        """
        start_time = time.time()
        
        # Extract key fields
        vuln_id = vuln.get("id", "unknown")
        plugin_name = vuln.get("pn", "")
        description = vuln.get("d", "")
        cve_id = vuln.get("c", "")
        cvss = vuln.get("cvss", 0.0)
        severity = vuln.get("s", 0)
        port = vuln.get("p", 0)
        host = vuln.get("h", "")
        
        # Try classification tiers
        classification = None
        source = "unknown"
        
        # Tier 1: CVE Lookup (if CVE exists)
        if cve_id and self.mode in ["hybrid", "cve"]:
            classification = self._classify_by_cve(cve_id, vuln)
            if classification:
                source = "cve_lookup"
                self.stats["cve_lookups"] += 1
        
        # Tier 2: Pattern Matching
        if not classification and self.mode in ["hybrid", "pattern"]:
            classification = self._classify_by_pattern(plugin_name, description, port)
            if classification and classification.get("confidence", 0) >= self.confidence_threshold:
                source = "pattern_match"
                self.stats["pattern_matches"] += 1
            else:
                classification = None  # Confidence too low
        
        # Tier 3: RAG-based Classification (if enabled and previous tiers failed)
        if not classification and self.enable_rag and self.mode in ["hybrid", "rag"]:
            classification = self._classify_by_rag(vuln)
            if classification:
                source = "rag_retrieval"
                self.stats["rag_classifications"] += 1
        
        # Fallback: Generic classification based on CVSS/severity
        if not classification:
            classification = self._generic_classification(vuln)
            source = "generic_fallback"
            self.stats["fallback_generic"] += 1
        
        # Enrich with RL agent hints
        classification = self._enrich_for_rl_agent(vuln, classification)
        
        # Add metadata
        classification["categorization_source"] = source
        
        # Calculate priority score
        priority_score = self._calculate_priority_score(vuln, classification)
        classification["priority_score"] = priority_score
        
        # Build final output
        processing_time = (time.time() - start_time) * 1000  # ms
        
        result = {
            "id": vuln_id,
            "original": vuln,
            "classification": classification,
            "metadata": {
                "classified_at": datetime.utcnow().isoformat() + "Z",
                "classifier_version": self.VERSION,
                "processing_time_ms": round(processing_time, 2)
            }
        }
        
        self.stats["total_classified"] += 1
        
        return result
    
    def _classify_by_cve(self, cve_id: str, vuln: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Classify using CVE lookup"""
        cve_data = self.kb.lookup_cve(cve_id)
        if not cve_data:
            return None
        
        return {
            "cwe": cve_data.get("cwe", []),
            "cwe_names": [self._get_cwe_name(cwe) for cwe in cve_data.get("cwe", [])],
            "mitre_attack": cve_data.get("mitre_attack", {}),
            "confidence": 0.95,
            "exploitation_assessment": {
                "difficulty": "Medium",
                "attack_vector": "Network",
                "requires_auth": False,
                "publicly_available_exploit": True
            }
        }
    
    def _classify_by_pattern(
        self, 
        plugin_name: str, 
        description: str, 
        port: int
    ) -> Optional[Dict[str, Any]]:
        """Classify using pattern matching"""
        # Match patterns
        matches = self.kb.match_pattern(description, plugin_name)
        
        if not matches:
            return None
        
        # Use best match
        best_match = matches[0]
        pattern_data = best_match["pattern_data"]
        
        return {
            "cwe": pattern_data.get("cwe", []),
            "cwe_names": pattern_data.get("cwe_names", []),
            "mitre_attack": pattern_data.get("mitre_attack", {}),
            "confidence": best_match["confidence"],
            "exploitation_assessment": {
                "difficulty": pattern_data.get("exploitation_difficulty", "Medium"),
                "attack_vector": "Network",
                "requires_auth": False,
                "publicly_available_exploit": pattern_data.get("exploitation_difficulty") == "Low"
            }
        }
    
    def _classify_by_rag(self, vuln: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Classify using RAG (Retrieval Augmented Generation)
        """
        if not self.llm:
            return None
        
        # Build prompt string manually since we use UniversalLLMClient
        system_prompt = """You are a cybersecurity expert specializing in vulnerability classification.
Categorize the following vulnerability for a penetration testing RL agent.

Respond with JSON containing:
- cwe: list of CWE IDs (e.g., ["CWE-89", "CWE-78"])
- cwe_names: list of CWE names
- mitre_attack: dict with tactics (list), techniques (list), technique_names (list)
- confidence: float 0-1
- exploitation_assessment: dict with difficulty (Low/Medium/High), attack_vector, requires_auth (bool), publicly_available_exploit (bool)

Be precise and conservative. If unsure, use generic categories.
Ensure output is valid JSON."""

        human_prompt = f"""Vulnerability:
- Name: {vuln.get("pn", "Unknown")}
- CVE: {vuln.get("c", "None")}
- CVSS: {vuln.get("cvss", 0)}
- Description: {vuln.get("d", "")[:500]}

Classify this vulnerability."""

        full_prompt = f"{system_prompt}\n\n{human_prompt}"
        
        try:
            # Use UniversalLLMClient to generate code (text)
            response_text = self.llm.generate_code(full_prompt)
            
            if not response_text:
                return None

            # Parse JSON
            # Strip code blocks if present
            clean_text = response_text.strip()
            if clean_text.startswith("```"):
                clean_text = clean_text.split("```")[1]
                if clean_text.startswith("json"):
                    clean_text = clean_text[4:]
            
            result = json.loads(clean_text)
            return result
            
        except Exception as e:
            print(f"WARNING: RAG classification failed: {e}")
            return None
    
    def _generic_classification(self, vuln: Dict[str, Any]) -> Dict[str, Any]:
        """Fallback generic classification based on severity and CVSS"""
        cvss = vuln.get("cvss", 0.0)
        severity = vuln.get("s", 0)
        
        # Generic categories based on severity
        if severity >= 4:
            cwe = ["CWE-1035"]  # Generic: 2011 Top 25
            cwe_names = ["Critical Weakness"]
        elif severity >= 3:
            cwe = ["CWE-699"]  # Generic: Software Development
            cwe_names = ["High Severity Weakness"]
        else:
            cwe = ["CWE-1008"]  # Generic: Architectural Concepts
            cwe_names = ["Medium/Low Severity Weakness"]
        
        return {
            "cwe": cwe,
            "cwe_names": cwe_names,
            "mitre_attack": {
                "tactics": ["Initial Access"],
                "techniques": ["T1190"],
                "technique_names": ["Exploit Public-Facing Application"]
            },
            "confidence": 0.3,  # Low confidence for generic classification
            "exploitation_assessment": {
                "difficulty": "Unknown",
                "attack_vector": "Network",
                "requires_auth": False,
                "publicly_available_exploit": False
            }
        }
    
    def _enrich_for_rl_agent(
        self, 
        vuln: Dict[str, Any], 
        classification: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Add RL agent-specific hints and guidance"""
        # Get pattern data if available for tool suggestions
        description = vuln.get("d", "")
        plugin_name = vuln.get("pn", "")
        matches = self.kb.match_pattern(description, plugin_name)
        
        suggested_tools = ["nmap", "metasploit"]
        attack_type = "generic_exploitation"
        validation_strategy = "Verify vulnerability through version detection or safe exploitation"
        expected_impact = "Potential system compromise"
        next_steps = ["enumerate_version", "search_exploits", "test_exploit"]
        
        if matches:
            pattern_data = matches[0]["pattern_data"]
            suggested_tools = pattern_data.get("suggested_tools", suggested_tools)
            attack_type = pattern_data.get("attack_type", attack_type)
        
        # Customize based on vulnerability type
        cvss = vuln.get("cvss", 0.0)
        if cvss >= 9.0:
            expected_impact = "Critical - Remote Code Execution or Full System Compromise"
            next_steps.insert(0, "prioritize_immediate_testing")
        
        classification["rl_agent_hints"] = {
            "attack_type": attack_type,
            "suggested_tools": suggested_tools,
            "validation_strategy": validation_strategy,
            "expected_impact": expected_impact,
            "next_steps": next_steps
        }
        
        return classification
    
    def _calculate_priority_score(
        self, 
        vuln: Dict[str, Any], 
        classification: Dict[str, Any]
    ) -> float:
        """
        Calculate priority score for RL agent (0-10)
        
        Factors:
        - CVSS score (base)
        - Exploitation difficulty (easier = higher priority)
        - Public exploit availability
        - Confidence in classification
        """
        cvss = vuln.get("cvss", 0.0)
        
        # Start with normalized CVSS
        score = cvss
        
        # Adjust for exploitation difficulty
        difficulty = classification.get("exploitation_assessment", {}).get("difficulty", "Medium")
        if difficulty == "Low":
            score += 1.0
        elif difficulty == "High":
            score -= 1.0
        
        # Boost if public exploit available
        if classification.get("exploitation_assessment", {}).get("publicly_available_exploit"):
            score += 0.5
        
        # Adjust for classification confidence
        confidence = classification.get("confidence", 0.5)
        score *= (0.7 + 0.3 * confidence)  # 70-100% of score based on confidence
        
        # Apply pattern-specific modifiers
        description = vuln.get("d", "")
        plugin_name = vuln.get("pn", "")
        matches = self.kb.match_pattern(description, plugin_name)
        if matches:
            pattern_data = matches[0]["pattern_data"]
            modifier = pattern_data.get("priority_modifier", 1.0)
            score *= modifier
        
        # Clamp to 0-10
        return min(10.0, max(0.0, score))
    
    def _get_cwe_name(self, cwe_id: str) -> str:
        """Get human-readable name for CWE ID"""
        # This is a simplified mapping. Full implementation would have complete CWE database
        cwe_names = {
            "CWE-89": "SQL Injection",
            "CWE-78": "OS Command Injection",
            "CWE-79": "Cross-site Scripting",
            "CWE-94": "Improper Control of Generation of Code",
            "CWE-119": "Improper Restriction of Operations within Memory Buffers",
            "CWE-120": "Buffer Copy without Checking Size of Input",
            "CWE-200": "Exposure of Sensitive Information",
            "CWE-287": "Improper Authentication",
            "CWE-306": "Missing Authentication for Critical Function",
            "CWE-327": "Use of Broken Cryptographic Algorithm",
            "CWE-338": "Use of Cryptographically Weak PRNG",
            "CWE-521": "Weak Password Requirements",
            "CWE-798": "Use of Hard-coded Credentials",
            "CWE-912": "Hidden Functionality",
            "CWE-1104": "Use of Unmaintained Third Party Components"
        }
        return cwe_names.get(cwe_id, cwe_id)
    
    def apply_filters(self, vulnerabilities: List[Dict[str, Any]], filters: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Apply filtering logic (migrated from vulncli)
        
        Args:
            vulnerabilities: List of vulnerability dicts
            filters: Filter configuration dict
            
        Returns:
            Filtered list of vulnerabilities
        """
        # Start with all
        filtered = vulnerabilities[:]
        
        filter_list = filters.get('filters', [])
        
        for filter_def in filter_list:
            if 'exclude_cve' in filter_def:
                cve = filter_def['exclude_cve']
                filtered = [v for v in filtered if v.get('c') != cve]
            
            elif 'exclude' in filter_def:
                exc = filter_def['exclude']
                filtered = self._apply_exclude(filtered, exc)
            
            elif 'include' in filter_def:
                inc = filter_def['include']
                filtered = self._apply_include(filtered, inc)
                
        return filtered
    
    def _apply_exclude(self, vulns: List[Dict[str, Any]], criteria: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Helper for exclude filters"""
        ports = criteria.get('ports')
        min_cvss = criteria.get('min_cvss')
        max_cvss = criteria.get('max_cvss')
        severity = criteria.get('severity')
        except_if = criteria.get('except_if')
        
        result = []
        for v in vulns:
            exclude = False
            
            if ports and v.get('p') in ports:
                exclude = True
            if min_cvss is not None and v.get('cvss', 0) >= min_cvss:
                exclude = True
            if max_cvss is not None and v.get('cvss', 0) <= max_cvss:
                exclude = True
            if severity is not None and v.get('s') in severity:
                exclude = True
                
            # Check exceptions
            if exclude and except_if:
                if 'family' in except_if and v.get('family', '') in except_if.get('family', []):
                    exclude = False
            
            if not exclude:
                result.append(v)
        return result

    def _apply_include(self, vulns: List[Dict[str, Any]], criteria: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Helper for include filters (keep ONLY if match)"""
        ports = criteria.get('ports')
        min_cvss = criteria.get('min_cvss')
        max_cvss = criteria.get('max_cvss')
        severity = criteria.get('severity')
        family = criteria.get('family')
        
        result = []
        for v in vulns:
            keep = True
            
            if ports and v.get('p') not in ports:
                keep = False
            if min_cvss is not None and v.get('cvss', 0) < min_cvss:
                keep = False
            if max_cvss is not None and v.get('cvss', 0) > max_cvss:
                keep = False
            if severity is not None and v.get('s') not in severity:
                keep = False
            if family and v.get('family', '') not in family:
                keep = False
                
            if keep:
                result.append(v)
        return result

    def generate_config_template(self) -> str:
        """Generate a default YAML configuration template for filters"""
        template = {
            "filters": [
                {
                    "exclude": {
                        "ports": [8080, 8443],
                        "min_cvss": 0.0,
                        "max_cvss": 3.0,
                        "severity": [0]
                    }
                },
                {
                    "exclude_cve": "CVE-2023-12345"
                },
                {
                    "include": {
                        "min_cvss": 7.0
                    }
                }
            ]
        }
        return yaml.dump(template, sort_keys=False)

    def classify_batch(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Classify multiple vulnerabilities
        
        Args:
            vulnerabilities: List of vulnerability dicts
        
        Returns:
            List of classified vulnerabilities
        """
        results = []
        total = len(vulnerabilities)
        
        for i, vuln in enumerate(vulnerabilities, 1):
            if i % 10 == 0 or i == total:
                print(f"Classifying: {i}/{total}")
            
            result = self.classify_vulnerability(vuln)
            results.append(result)
        
        return results
    
    def get_stats(self) -> Dict[str, Any]:
        """Get classification statistics"""
        return self.stats.copy()


def classify_from_file(
    input_file: str,
    output_file: Optional[str] = None,
    mode: str = "hybrid",
    enable_rag: bool = False
) -> List[Dict[str, Any]]:
    """
    Convenience function to classify vulnerabilities from JSON file
    
    Args:
        input_file: Path to input JSON file (parser output)
        output_file: Optional path to save enriched output
        mode: Classification mode
        enable_rag: Enable RAG-based classification
    
    Returns:
        List of classified vulnerabilities
    """
    # Load input
    with open(input_file, 'r') as f:
        vulnerabilities = json.load(f)
    
    # Ensure it's a list
    if isinstance(vulnerabilities, dict):
        # Handle full format with metadata
        if "vulnerabilities" in vulnerabilities:
            # Extract all vulnerabilities from severity buckets
            all_vulns = []
            for severity in ["critical", "high", "medium", "low", "info"]:
                all_vulns.extend(vulnerabilities["vulnerabilities"].get(severity, []))
            vulnerabilities = all_vulns
        else:
            vulnerabilities = [vulnerabilities]
    
    # Classify
    classifier = VulnerabilityClassifier(mode=mode, enable_rag=enable_rag)
    results = classifier.classify_batch(vulnerabilities)
    
    # Print stats
    print("\nClassification Stats:")
    for key, value in classifier.get_stats().items():
        print(f"  {key}: {value}")
    
    # Save if output file specified
    if output_file:
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"\nSaved to: {output_file}")
    
    return results


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python vulnerability_classifier.py <input_file> [output_file]")
        print("\nExample:")
        print("  python vulnerability_classifier.py VA_Output/critical_ms2_scan.json classified_output.json")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    results = classify_from_file(input_file, output_file, mode="hybrid", enable_rag=False)
    
    if not output_file:
        # Print first result as sample
        if results:
            print("\nSample classification:")
            print(json.dumps(results[0], indent=2))
